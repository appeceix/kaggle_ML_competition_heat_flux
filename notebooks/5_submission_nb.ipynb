{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Exportar/importar modelos\n",
    "import pickle\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo el modelo desde el archivo .pickle\n",
    "model = pickle.load(open('../output/models/quinto_procesado_quinto_modelo_a_xgboost.pickle', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('estimator',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=1, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "                              importance_type=None, interaction_constraints='',\n",
       "                              learning_rate=0.1, max_bin=256,\n",
       "                              max_cat_to_onehot=4, max_delta_step=0,\n",
       "                              max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, reg_alpha=0,\n",
       "                              reg_lambda=1, ...))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21229 entries, 0 to 21228\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   pressure [MPa]       21229 non-null  float64\n",
      " 1   mass_flux [kg/m2-s]  21229 non-null  float64\n",
      " 2   x_e_out [-]          21229 non-null  float64\n",
      " 3   D_e [mm]             21229 non-null  float64\n",
      " 4   D_h [mm]             21229 non-null  float64\n",
      " 5   length [mm]          21229 non-null  float64\n",
      " 6   chf_exp [MW/m2]      21229 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv('../data/raw_data/data.csv')\n",
    "df_features_rellenas = pd.read_csv('../data/processed/quinto_procesado_a_entrenamiento.csv', sep='\\t')\n",
    "df_target = pd.read_csv('../data/processed/quinto_procesado_a_target.csv', sep='\\t')\n",
    "df_features_rellenas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prado\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- D_e [mm]\n",
      "- D_h [mm]\n",
      "- chf_exp [MW/m2]\n",
      "- length [mm]\n",
      "- mass_flux [kg/m2-s]\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- D_e\n",
      "- D_h\n",
      "- chf_exp\n",
      "- length\n",
      "- mass_flux\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Divido df_target en X e y. y es x_e_out [-]\n",
    "X = df_target.drop('x_e_out [-]', axis = 1)\n",
    "y = df_target['x_e_out [-]']\n",
    "# Predigo con el modelo\n",
    "y_pred = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred, columns = ['x_e_out [-]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos el campo id, que coincide con el id de df_original donde x_e_out [-] es NaN\n",
    "y_pred['id'] = df_original[df_original['x_e_out [-]'].isna()]['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'x_e_out [-]'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cambiamos el orde de las columnas para que x_e_out [-] sea la última\n",
    "y_pred = y_pred[['id', 'x_e_out [-]']]\n",
    "y_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el dataframe con las predicciones para hacer submit\n",
    "y_pred.to_csv('../output/submissions/5_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
