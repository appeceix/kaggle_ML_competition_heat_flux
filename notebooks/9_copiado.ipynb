{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.07490830634422771\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/raw_data/data.csv')\n",
    "\n",
    "# Separate the 'id' column\n",
    "id_col = data.pop('id')\n",
    "\n",
    "# One-Hot Encoding\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Split the dataset into a set with missing values and a set with known values of 'x_e_out [-]'\n",
    "unknown = data[data['x_e_out [-]'].isna()]\n",
    "known = data.dropna(subset=['x_e_out [-]'])\n",
    "\n",
    "# Set 'x_e_out [-]' as the target variable, and the rest of the columns as features\n",
    "X_known = known.drop('x_e_out [-]', axis=1)\n",
    "y_known = known['x_e_out [-]']\n",
    "\n",
    "X_unknown = unknown.drop('x_e_out [-]', axis=1)\n",
    "\n",
    "# Apply the imputer\n",
    "imputer = SimpleImputer(strategy='median')  # or use 'mean' as per your preference\n",
    "X_known_imputed = imputer.fit_transform(X_known)\n",
    "X_known = pd.DataFrame(X_known_imputed, columns=X_known.columns)\n",
    "\n",
    "X_unknown_imputed = imputer.transform(X_unknown)\n",
    "X_unknown = pd.DataFrame(X_unknown_imputed, columns=X_unknown.columns)\n",
    "\n",
    "# Split the known data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_known, y_known, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure valid column names for LightGBM\n",
    "X_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train.columns]\n",
    "X_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_test.columns]\n",
    "X_unknown.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_unknown.columns]\n",
    "\n",
    "# Initialize and train the model\n",
    "model = lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and evaluate\n",
    "preds_test = model.predict(X_test)\n",
    "print('Test RMSE:', np.sqrt(mean_squared_error(y_test, preds_test)))\n",
    "\n",
    "# Predict missing values\n",
    "preds_unknown = model.predict(X_unknown)\n",
    "\n",
    "# Combine the original id column with the predicted values for unknown 'x_e_out [-]'\n",
    "predicted_unknown = pd.DataFrame({'id': id_col[unknown.index], 'x_e_out [-]': preds_unknown})\n",
    "\n",
    "# Save the predictions to a csv file\n",
    "predicted_unknown.to_csv('submission_LGBMRegressor.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622ae8f9bba74fea91a5db9c98115f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/550 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.00560602011743376\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.00560602011743376\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.0055671926027358026\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.005546412535895953\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.005546412535895953\n",
      "\n",
      "Generation 6 - Current best internal CV score: -0.005546412535895953\n",
      "\n",
      "Generation 7 - Current best internal CV score: -0.005541459971641045\n",
      "\n",
      "Generation 8 - Current best internal CV score: -0.0055289150152443515\n",
      "\n",
      "Generation 9 - Current best internal CV score: -0.0055289150152443515\n",
      "\n",
      "Generation 10 - Current best internal CV score: -0.0055289150152443515\n",
      "\n",
      "Best pipeline: RandomForestRegressor(input_matrix, bootstrap=True, max_features=0.4, min_samples_leaf=8, min_samples_split=14, n_estimators=100)\n",
      "Imputing missing values in feature set\n",
      "Test RMSE: 0.07487869851087404\n",
      "Imputing missing values in feature set\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/raw_data/data.csv')\n",
    "\n",
    "# Separate the 'id' column\n",
    "id_col = data.pop('id')\n",
    "\n",
    "# One-Hot Encoding\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Split the dataset into a set with missing values and a set with known values of 'x_e_out [-]'\n",
    "unknown = data[data['x_e_out [-]'].isna()]\n",
    "known = data.dropna(subset=['x_e_out [-]'])\n",
    "\n",
    "# Set 'x_e_out [-]' as the target variable, and the rest of the columns as features\n",
    "X_known = known.drop('x_e_out [-]', axis=1)\n",
    "y_known = known['x_e_out [-]']\n",
    "\n",
    "X_unknown = unknown.drop('x_e_out [-]', axis=1)\n",
    "\n",
    "# Split the known data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_known, y_known, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_unknown = scaler.transform(X_unknown)\n",
    "\n",
    "# Initialize and train the AutoML model using TPOT\n",
    "tpot = TPOTRegressor(generations=10, population_size=50, random_state=42, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the AutoML model on the test set\n",
    "preds_test = tpot.predict(X_test)\n",
    "print('Test RMSE:', np.sqrt(mean_squared_error(y_test, preds_test)))\n",
    "\n",
    "# Predict missing values using the AutoML model\n",
    "preds_unknown = tpot.predict(X_unknown)\n",
    "\n",
    "# Combine the original id column with the predicted values for unknown 'x_e_out [-]'\n",
    "predicted_unknown = pd.DataFrame({'id': id_col[unknown.index], 'x_e_out [-]': preds_unknown})\n",
    "\n",
    "# Save the predictions to a csv file\n",
    "predicted_unknown.to_csv('submission_AutoML.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
