{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#importamos pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# importamos one hot encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# importamos el imputador de variables\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('../data/raw_data/data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rellenamos las variables categóricas con Thompson y tube porque son las que más se repiten, con diferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thompson        17396\n",
       "Janssen          2716\n",
       "Weatherhead      2040\n",
       "Beus             1604\n",
       "Peskov           1084\n",
       "Williams          891\n",
       "Richenderfer      545\n",
       "Mortimore         197\n",
       "Kossolapov        101\n",
       "Inasaka            46\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contamos los distintos valores de Author\n",
    "data_raw['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled = data_raw.copy()\n",
    "\n",
    "data_filled['author'] = data_filled['author'].fillna('Thompson')\n",
    "data_filled['geometry'] = data_filled['geometry'].fillna('tube')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31644 entries, 0 to 31643\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   31644 non-null  int64  \n",
      " 1   author               31644 non-null  object \n",
      " 2   geometry             31644 non-null  object \n",
      " 3   pressure [MPa]       27192 non-null  float64\n",
      " 4   mass_flux [kg/m2-s]  26853 non-null  float64\n",
      " 5   x_e_out [-]          21229 non-null  float64\n",
      " 6   D_e [mm]             26156 non-null  float64\n",
      " 7   D_h [mm]             27055 non-null  float64\n",
      " 8   length [mm]          26885 non-null  float64\n",
      " 9   chf_exp [MW/m2]      31644 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_filled.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estas variables numéricas las rellenamos con la media, ya que es más adecuado para su distribución.\n",
    "### mass_flux, D_h [mm], length [mm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos data_filled con la media de cada columna para mass_flux [kg/m2-s], D_h[mm], length [mm]\n",
    "data_filled['mass_flux [kg/m2-s]'] = data_filled['mass_flux [kg/m2-s]'].fillna(data_filled['mass_flux [kg/m2-s]'].mean())\n",
    "data_filled['D_h [mm]'] = data_filled['D_h [mm]'].fillna(data_filled['D_h [mm]'].mean())\n",
    "data_filled['length [mm]'] = data_filled['length [mm]'].fillna(data_filled['length [mm]'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31644 entries, 0 to 31643\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   31644 non-null  int64  \n",
      " 1   author               31644 non-null  object \n",
      " 2   geometry             31644 non-null  object \n",
      " 3   pressure [MPa]       27192 non-null  float64\n",
      " 4   mass_flux [kg/m2-s]  31644 non-null  float64\n",
      " 5   x_e_out [-]          21229 non-null  float64\n",
      " 6   D_e [mm]             26156 non-null  float64\n",
      " 7   D_h [mm]             31644 non-null  float64\n",
      " 8   length [mm]          31644 non-null  float64\n",
      " 9   chf_exp [MW/m2]      31644 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_filled.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estas variables numéricas las rellenamos con la moda, ya que es más adecuado para su distribución.\n",
    "### D_e [mm],  pressure [MPa]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos data_filled con la media de cada columna para D_h[mm], pressure [MPa]\n",
    "data_filled['D_e [mm]'] = data_filled['D_e [mm]'].fillna(data_filled['D_e [mm]'].mean())\n",
    "data_filled['pressure [MPa]'] = data_filled['pressure [MPa]'].fillna(data_filled['pressure [MPa]'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31644 entries, 0 to 31643\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   31644 non-null  int64  \n",
      " 1   author               31644 non-null  object \n",
      " 2   geometry             31644 non-null  object \n",
      " 3   pressure [MPa]       31644 non-null  float64\n",
      " 4   mass_flux [kg/m2-s]  31644 non-null  float64\n",
      " 5   x_e_out [-]          21229 non-null  float64\n",
      " 6   D_e [mm]             31644 non-null  float64\n",
      " 7   D_h [mm]             31644 non-null  float64\n",
      " 8   length [mm]          31644 non-null  float64\n",
      " 9   chf_exp [MW/m2]      31644 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_filled.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividimos el dataset, quitando las que tengan null en x_e_out [-]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset, dejando aparte las filas que tengan nan en x_e_out [-]\n",
    "data_filled_con_nan = data_filled[data_filled['x_e_out [-]'].isna()].copy()\n",
    "data_filled_sin_nan = data_filled.dropna(subset=['x_e_out [-]']).drop(columns=['id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10415 entries, 4 to 31642\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   10415 non-null  int64  \n",
      " 1   author               10415 non-null  object \n",
      " 2   geometry             10415 non-null  object \n",
      " 3   pressure [MPa]       10415 non-null  float64\n",
      " 4   mass_flux [kg/m2-s]  10415 non-null  float64\n",
      " 5   x_e_out [-]          0 non-null      float64\n",
      " 6   D_e [mm]             10415 non-null  float64\n",
      " 7   D_h [mm]             10415 non-null  float64\n",
      " 8   length [mm]          10415 non-null  float64\n",
      " 9   chf_exp [MW/m2]      10415 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 895.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_filled_con_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos entre features y target\n",
    "X = data_filled_sin_nan.drop('x_e_out [-]', axis = 1).drop('author', axis = 1).drop('geometry', axis = 1)\n",
    "y = data_filled_sin_nan['x_e_out [-]']\n",
    "\n",
    "# Dividimos entre train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un preprocessor\n",
    "# categorical_columns = ['author', 'geometry']  # Columnas categóricas\n",
    "# numeric_columns = ['mass_flux [kg/m2-s]', 'D_h [mm]', 'length [mm]', 'D_e [mm]', 'pressure [MPa]', 'chf_exp [MW/m2]']  # Columnas numéricas\n",
    "# dummy_encoder = OneHotEncoder(drop='first')\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('dummy', dummy_encoder, categorical_columns),\n",
    "#         ('scale', scaler, numeric_columns)\n",
    "#     ],\n",
    "#     remainder='passthrough'  # Pass through any other columns without transformation\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('RandomForest', RandomForestRegressor())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos un pipeline con varios modelos de regresión\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    # ('preprocessor', preprocessor),\n",
    "    ('RandomForest', RandomForestRegressor()),\n",
    "    # ('RandomForestRegressor', RandomForestRegressor())\n",
    "    # ('SVR', SVR()),\n",
    "    # ('Ridge', Ridge()),\n",
    "    # ('Lasso', Lasso()),\n",
    "    # ('ElasticNet', ElasticNet())\n",
    "])\n",
    "\n",
    "# Entrenamos el pipeline\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.084709  ,  0.075518  ,  0.18069433, ..., -0.110803  ,\n",
       "        0.021973  ,  0.01807125])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.07928563522636922\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos con el RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'RMSE: {rmse}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar el CSV para la submission de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.to_csv('../output/submissions/submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.084709  ,  0.075518  ,  0.18069433, ..., -0.110803  ,\n",
       "        0.021973  ,  0.01807125])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
